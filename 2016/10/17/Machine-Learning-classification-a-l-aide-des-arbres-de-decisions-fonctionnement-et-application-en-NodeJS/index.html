<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Machine Learning : classification à l&#39;aide des arbres de décisions : fonctionnement et application en NodeJS | M@XCode</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="google-site-verification" content="zhe_jVE6TPFbrQb7K-ra2FFxgiDsn6ZeFoKSz9EXmGk" />
  <meta name="description" content="Qu’est ce qu’un arbre de décisionsUn arbre de décision est une représentation visuelle d’un algorithme de classification de données suivant différents critères qu’on appellera décisions (ou noeuds). V">
<meta property="og:type" content="article">
<meta property="og:title" content="Machine Learning : classification à l'aide des arbres de décisions : fonctionnement et application en NodeJS">
<meta property="og:url" content="http://maximilienandile.github.io/2016/10/17/Machine-Learning-classification-a-l-aide-des-arbres-de-decisions-fonctionnement-et-application-en-NodeJS/index.html">
<meta property="og:site_name" content="M@XCode">
<meta property="og:description" content="Qu’est ce qu’un arbre de décisionsUn arbre de décision est une représentation visuelle d’un algorithme de classification de données suivant différents critères qu’on appellera décisions (ou noeuds). V">
<meta property="og:image" content="http://maximilienandile.github.io/images/arbre_de_decision.png">
<meta property="og:image" content="http://maximilienandile.github.io/images/arbre_de_decision_vocabulaire.png">
<meta property="og:updated_time" content="2016-10-28T15:28:00.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Machine Learning : classification à l'aide des arbres de décisions : fonctionnement et application en NodeJS">
<meta name="twitter:description" content="Qu’est ce qu’un arbre de décisionsUn arbre de décision est une représentation visuelle d’un algorithme de classification de données suivant différents critères qu’on appellera décisions (ou noeuds). V">
<meta name="twitter:image" content="http://maximilienandile.github.io/images/arbre_de_decision.png">
  
    <link rel="alternate" href="/atom.xml" title="M@XCode" type="application/atom+xml">
  
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" integrity="sha384-XdYbMnZ/QjLh6iI4ogqCTaIjrFk87ip+ekIjefZch0Y+PvJ8CDYtEs1ipDmPorQ+" crossorigin="anonymous">

  <link rel="stylesheet" href="/css/styles.css">
  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-77397884-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics --><!-- hexo-inject:begin --><!-- hexo-inject:end -->


</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><nav class="navbar navbar-inverse">
  <div class="container">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#main-menu-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="main-menu-navbar">
      <ul class="nav navbar-nav">
        
          <li><a class=""
                 href="/index.html">Home</a></li>
        
          <li><a class=""
                 href="/archives/">Archives</a></li>
        
      </ul>

      <!--
      <ul class="nav navbar-nav navbar-right">
        
          <li><a href="/atom.xml" title="RSS Feed"><i class="fa fa-rss"></i></a></li>
        
      </ul>
      -->
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>

  <div class="container">
    <div class="blog-header">
  <h3 class="blog-title">M@XCode</h3>
  
</div>

    <div class="row">
        <div class="col-sm-8 blog-main">
          <article id="post-Machine-Learning-classification-a-l-aide-des-arbres-de-decisions-fonctionnement-et-application-en-NodeJS" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 class="article-title" itemprop="name">
      Machine Learning : classification à l&#39;aide des arbres de décisions : fonctionnement et application en NodeJS
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="/2016/10/17/Machine-Learning-classification-a-l-aide-des-arbres-de-decisions-fonctionnement-et-application-en-NodeJS/" class="article-date"><time datetime="2016-10-17T16:39:24.000Z" itemprop="datePublished">17/10/2016</time></a>
</div>

    
    

  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Qu’est-ce-qu’un-arbre-de-decisions"><a href="#Qu’est-ce-qu’un-arbre-de-decisions" class="headerlink" title="Qu’est ce qu’un arbre de décisions"></a>Qu’est ce qu’un arbre de décisions</h2><p>Un arbre de décision est une représentation visuelle d’un algorithme de classification de données suivant différents critères qu’on appellera décisions (ou noeuds). Voici un exemple :</p>
<p><img src="/images/arbre_de_decision.png" alt="Exemple d&#39;un arbre de décision pour l&#39;accord d&#39;un prêt"></p>
<p>Cet arbre de décision permet en fonction de <strong>quelques questions de déterminer si une banque doit prêter ou pas au client</strong> qui demande un prêt. Ce dernier est très simplifié mais la plupart des banques utilisent des systèmes similaires permettant aux agents une prise de décision experte.</p>
<p>Mais comment arrive t’on à de telles règles de décisions. Dans les faits il s’agit de synthétiser la connaissance et l’historique de l’ensemble des prêts accordés par la banque et de classer chacun de ces prêts selon qu’ils aient été remboursés sans incident ou pas. <strong>Il s’agit donc de trouver dans une énorme quantité de données les questions qu’il est judicieux de poser afin de prédire la qualité d’un emprunteur.</strong></p>
<h2 id="Vocabulaire"><a href="#Vocabulaire" class="headerlink" title="Vocabulaire"></a>Vocabulaire</h2><p>Nous allons détailler la construction d’un tel arbre de décision. Posons d’abord quelques mots de vocabulaire. On va classer des objets.</p>
<ul>
<li>Chaque objet de la données historique (set d’entraînement) dispose d’une <strong>classe</strong> bien définie</li>
<li>Chaque objet (par exemple un prêt accordé à monsieur X) dispose de <strong>features</strong>, de propriétés bien définies elles aussi. Par exemple : la personne a qui on a accordé le prêt possédait-elle une maison, possédait elle un CDI ?</li>
<li>Chaque <strong>propriété</strong> ou <strong>feature</strong> a un ensemble de valeurs possibles. Par exemple (‘oui’ ou ‘non’)</li>
</ul>
<p>Dans notre graphique représentant l’arbre de décision on a les éléments suivants :</p>
<ul>
<li>Un noeud de décision (représenté par un rectangle) (on pose une question)</li>
<li>Un <strong>bloc de fin</strong> qui est représenté par un oval. (on a trouvé la classe)</li>
</ul>
<p><img src="/images/arbre_de_decision_vocabulaire.png" alt="Vocabulaire de l&#39;arbre de décision"></p>
<h2 id="Fonctionnement-de-l’algorithme-un-exemple"><a href="#Fonctionnement-de-l’algorithme-un-exemple" class="headerlink" title="Fonctionnement de l’algorithme : un exemple"></a>Fonctionnement de l’algorithme : un exemple</h2><p>Dans les faits on aura en entrée de notre algorithme une série de données qui représentera de nombreux <strong>objets</strong> (ici des prêts) ayant chacun un set de <strong>propriétés</strong> (ici : CDI oui ou Non, Locataire oui ou non …). Ces objets du set d’entrainement seront déjà <strong>classés</strong> (ex: Bon Emprunteur).Par exemple :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">Prêt 1 : CDI : 1 - Locataire : 1 - Classe : Bon emprunteur</div><div class="line">Prêt 2 : CDI : 0 - Locataire : 0 - Classe : Bon emprunteur</div><div class="line">Prêt 3 : CDI : 1 - Locataire : 1 - Classe : Bon emprunteur</div><div class="line">Prêt 4 : CDI : 0 - Locataire : 0 - Classe : Mauvais emprunteur</div><div class="line">Prêt 5 : CDI : 1 - Locataire : 1 - Classe : Bon emprunteur</div><div class="line">...</div></pre></td></tr></table></figure>
<p>Notre algorithme va donc devoir choisir une première question à poser à notre candidat. Pour cela il doit choisir la <strong>feature</strong> (ou propriété) qui permet de découper nos prêts en <strong>deux sets les plus homogènes possibles</strong>, c’est à dire deux sets regroupant des prêts dont les emprunteurs sont en grande partie d’une même catégorie.</p>
<p>Par exemple l’algorithme va tester la <strong>feature CDI</strong> et va ensuite répartir les prêts dans deux set : les prêts fait par des personnes en CDI et les autres. Si dans un des set on trouve que des prêts ayant la même classe alors <strong>l’algorithme s’arrêtera pour cette branche</strong>. Par exemple si on constate que tous les gens qui n’ont pas de CDI sont des mauvais emprunteurs alors on peut s’arrêter là et dire à nos agents de ne plus prêter aux gens sans CDI.</p>
<p>Si on a pas obtenu un set composé de prêts qui ont la même classe après ce premier split, on va ensuite refaire le même travail pour les features suivantes. Nous allons sélectionner la feature permettant un classement le plus homogène possible… <strong>Ce processus est mené jusqu’à ce qu’o obtiennent des classes homogènes.</strong></p>
<h2 id="Overfitting-et-extraction-de-sens"><a href="#Overfitting-et-extraction-de-sens" class="headerlink" title="Overfitting et extraction de sens"></a>Overfitting et extraction de sens</h2><p>Cet algorithme est peu gourmand en mémoire. Mais il y a un risque très important d’<strong>overfitting</strong>, c’est à dire que l’arbre n’est pas utilisable car il fournit des résultats très bon pour le set d’entraînement, mais utilisé en conditions réelles il classe très mal les nouveaux exemples. Pour cela on peut envisager d’avoir couper notre set d’entrainement en deux afin d’avoir un set de données permettant de valider si il y a <strong>overfitting</strong> ou pas.</p>
<p>Cet algorithme est <strong>très intéressant pour extraire de l’information d’une source de données obscure</strong>. Il permet d’<strong>isoler les propriétés</strong> ou features qui apportent le plus d’information pour <strong>déterminer la classe de chaque objet</strong>.</p>
<h2 id="Application-en-NodeJS"><a href="#Application-en-NodeJS" class="headerlink" title="Application en NodeJS"></a>Application en NodeJS</h2><h3 id="Calcul-de-l’entropie-de-Shannon"><a href="#Calcul-de-l’entropie-de-Shannon" class="headerlink" title="Calcul de l’entropie de Shannon"></a>Calcul de l’entropie de Shannon</h3><p>Dans le paragraphe précédent nous disions qu’il fallait trouver la feature générant des classes qui sont les plus homogènes possibles. Mais comment définir cette <strong>homogénéité</strong> ?</p>
<p>Nous allons utiliser un résultat important de la <strong>théorie mathématique de l’information</strong> : l’entropie. Et plus particulièrement l’entropie de <strong>Shannon</strong> :</p>
<center><br><span>$H=-\sum_{i=1}^{n} P(x_{i})log_{2}(P(x_{i}) )$</span><!-- Has MathJax --><br></center>

<p><strong>L’entropie correspond au désordre</strong>. Plus on a de classes différentes dans un set de données plus l’entropie sera grande. De manière opposée si dans un set de données tous les objets ont la même classe, il n’y aura <strong>pas de désordre l’entropie sera nulle</strong>.</p>
<p>Dans les faits on va calculer l’entropie de la manière suivante en NodeJS :</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> _ = <span class="built_in">require</span>(<span class="string">'lodash'</span>);</div><div class="line"><span class="comment">/**</span></div><div class="line">* This function is used to compute the Shannon Entropy</div><div class="line">* @method calculate_shannon_entropy</div><div class="line">* @param  &#123;Array&#125;                  data an array of data</div><div class="line">* @return &#123;Number&#125;                       The Shannon Entropy</div><div class="line">*/</div><div class="line"><span class="keyword">var</span> calculate_shannon_entropy=<span class="function"><span class="keyword">function</span>(<span class="params">data</span>)</span>&#123;</div><div class="line"></div><div class="line">  <span class="comment">// init the shannon Entropy</span></div><div class="line">  <span class="keyword">var</span> shannon_entropy = <span class="number">0</span>;</div><div class="line">  <span class="comment">// we get the number of entries in the array</span></div><div class="line">  <span class="keyword">var</span> length_of_data = data.length;</div><div class="line">  <span class="comment">// create an empty array to keep track of different labels</span></div><div class="line">  <span class="keyword">var</span> labels_counter = &#123;&#125;</div><div class="line">  <span class="comment">// we iterate through the array</span></div><div class="line">  _.forEach(data, <span class="function"><span class="keyword">function</span>(<span class="params">value, key</span>) </span>&#123;</div><div class="line">    <span class="comment">// extract the label from the one data element</span></div><div class="line">    <span class="keyword">var</span> label_extracted = value.label;</div><div class="line">    <span class="comment">// check if this label is inside our label counter array</span></div><div class="line">    <span class="keyword">if</span> (label_extracted <span class="keyword">in</span> labels_counter)&#123;</div><div class="line">      <span class="comment">// the element is inside our object increment its value</span></div><div class="line">      labels_counter[label_extracted] +=<span class="number">1</span></div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      labels_counter[label_extracted] = <span class="number">1</span></div><div class="line">    &#125;</div><div class="line">  &#125;);</div><div class="line"></div><div class="line">  <span class="comment">// We then iterate through our label counter object</span></div><div class="line">  _.forEach(labels_counter, <span class="function"><span class="keyword">function</span>(<span class="params">value, key</span>) </span>&#123;</div><div class="line">    <span class="comment">// we get the frequency of the number of time a label occurs</span></div><div class="line">    <span class="keyword">var</span> p = <span class="built_in">parseFloat</span>(value/length_of_data)</div><div class="line">    <span class="comment">// Caculate the entropy of a class and add it to the shannon_entropy variable</span></div><div class="line">    shannon_entropy -= p * getBaseLog(<span class="number">2</span>,p)</div><div class="line"></div><div class="line">  &#125;)</div><div class="line"></div><div class="line">  <span class="keyword">return</span> shannon_entropy</div><div class="line"></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">* This function return the log of Y in base X</div><div class="line">* @method getBaseLog</div><div class="line">* @param  &#123;Number&#125;   x base</div><div class="line">* @param  &#123;Number&#125;   y number</div><div class="line">* @return &#123;Number&#125;     the log of Y in base X</div><div class="line">*/</div><div class="line"><span class="keyword">var</span> getBaseLog=<span class="function"><span class="keyword">function</span>(<span class="params">x, y</span>) </span>&#123;</div><div class="line">  <span class="keyword">return</span> <span class="built_in">Math</span>.log(y) / <span class="built_in">Math</span>.log(x);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">var</span> a = [</div><div class="line">  &#123;<span class="string">"has_a_car"</span>:<span class="number">1</span>, <span class="string">"has_a_house"</span>:<span class="number">1</span>, <span class="string">"has_children"</span>:<span class="number">1</span>,<span class="string">"label"</span>:<span class="string">"bon_emprunteur"</span>&#125;,</div><div class="line">  &#123;<span class="string">"has_a_car"</span>:<span class="number">1</span>, <span class="string">"has_a_house"</span>:<span class="number">1</span>, <span class="string">"has_children"</span>:<span class="number">0</span>,<span class="string">"label"</span>:<span class="string">"bon_emprunteur"</span>&#125;,</div><div class="line">  &#123;<span class="string">"has_a_car"</span>:<span class="number">1</span>, <span class="string">"has_a_house"</span>:<span class="number">0</span>, <span class="string">"has_children"</span>:<span class="number">1</span>,<span class="string">"label"</span>:<span class="string">"bon_emprunteur"</span>&#125;,</div><div class="line">  &#123;<span class="string">"has_a_car"</span>:<span class="number">0</span>, <span class="string">"has_a_house"</span>:<span class="number">0</span>, <span class="string">"has_children"</span>:<span class="number">0</span>,<span class="string">"label"</span>:<span class="string">"mauvais_emprunteur"</span>&#125;,</div><div class="line">  &#123;<span class="string">"has_a_car"</span>:<span class="number">0</span>, <span class="string">"has_a_house"</span>:<span class="number">0</span>, <span class="string">"has_children"</span>:<span class="number">1</span>,<span class="string">"label"</span>:<span class="string">"mauvais_emprunteur"</span>&#125;</div><div class="line">]</div><div class="line">calculate_shannon_entropy(a)</div><div class="line"><span class="comment">// returns 0.9709505944546686</span></div></pre></td></tr></table></figure>
<p>On prend donc la fréquence d’apparition de la classe <code>bon_emprunteur</code> et son log en base 2 auquel on va ajouter moins la fréquence d’apparition de la classe <code>mauvais_emprunteur</code> et son log en base 2 !</p>
<p>Il va falloir ensuite que l’on puisse éliminer des features au fur et à mesure que l’on split notre données au fil des blocs de décision. C’est l’objet de la partie suivante :</p>
<h3 id="Creation-de-la-fonction-permettant-de-partitionner-un-set-de-donnees-en-fonction-d’une-feature-et-de-sa-valeur"><a href="#Creation-de-la-fonction-permettant-de-partitionner-un-set-de-donnees-en-fonction-d’une-feature-et-de-sa-valeur" class="headerlink" title="Création de la fonction permettant de partitionner un set de données en fonction d’une feature et de sa valeur"></a>Création de la fonction permettant de partitionner un set de données en fonction d’une feature et de sa valeur</h3><p>Notre mission ensuite est de préparer la fonction qui permet à partir d’un set de données d’entrainement de récupérer un set plus petit ne contenant plus que les objets disposant de cette feature dont la valeur est égale à une des valeurs possibles de la feature.</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">* This function split our dataset and extract object that have the feature set to a specific value</div><div class="line">* @method split_the_dataset_by_feature_and_value</div><div class="line">* @param  &#123;Array of Object&#125;                               data    our dataset</div><div class="line">* @param  &#123;String&#125;                               feature the name of the feature</div><div class="line">* @param  &#123;String or Number&#125;                               value   the value of the feature to extract from the dataset</div><div class="line">* @return  &#123;Array of Object&#125;                               value   the dataset without the objects that have the feature "feature" set to the value "value" &amp; without the feature "feature"</div><div class="line">*/</div><div class="line"><span class="keyword">var</span> split_the_dataset_by_feature_and_value=<span class="function"><span class="keyword">function</span>(<span class="params">data_set,feature,value</span>)</span>&#123;</div><div class="line">  <span class="comment">// we partition our array in order to isolate in the data</span></div><div class="line">  <span class="comment">// Objects that have the `feature` set to the right value</span></div><div class="line">  <span class="keyword">var</span> data_set</div><div class="line"></div><div class="line"></div><div class="line">  <span class="keyword">var</span> array_partitioned = _.filter(data_set, <span class="function"><span class="keyword">function</span>(<span class="params">o</span>) </span>&#123; <span class="keyword">return</span> o[feature]==value; &#125;);</div><div class="line">  <span class="comment">// we then have to remove the feature from our objects</span></div><div class="line">  <span class="keyword">var</span> array_to_return = []</div><div class="line"></div><div class="line"></div><div class="line">  array_partitioned.forEach(<span class="function"><span class="keyword">function</span>(<span class="params">v</span>)</span>&#123;</div><div class="line">    <span class="keyword">var</span> new_object = &#123;&#125;</div><div class="line">    _.forEach(v, <span class="function"><span class="keyword">function</span>(<span class="params">value, key</span>) </span>&#123;</div><div class="line"></div><div class="line">        <span class="keyword">if</span>(key!==feature)&#123;</div><div class="line">          new_object[key]=value</div><div class="line">        &#125;</div><div class="line">      &#125;);</div><div class="line">    array_to_return.push(new_object)</div><div class="line"></div><div class="line">  &#125;);</div><div class="line"></div><div class="line">  <span class="keyword">return</span> array_to_return</div><div class="line">&#125;</div><div class="line"></div><div class="line">split_the_dataset_by_feature_and_value(a,<span class="string">"has_a_house"</span>,<span class="number">0</span>)</div><div class="line"><span class="comment">// returns</span></div><div class="line"><span class="comment">// [ &#123; has_a_car: 1, has_children: 1, label: 'bon_emprunteur' &#125;,</span></div><div class="line"><span class="comment">//  &#123; has_a_car: 0, has_children: 0, label: 'mauvais_emprunteur' &#125;,</span></div><div class="line"><span class="comment">//  &#123; has_a_car: 0, has_children: 1, label: 'mauvais_emprunteur' &#125; ]</span></div></pre></td></tr></table></figure>
<p>Par exemple ici nous nous débarassons des objets dans notre set de données dont la feature <code>has_a_house</code> est différent de 0.</p>
<p>Maintenant attaquons nous au coeur du réacteur : nous devons trouver la meilleur feature, autrement dit celle qui génère le moins d’entropie (on parle aussi de <strong>gain informationnel maximal</strong>)…</p>
<h3 id="Determiner-la-feature-dans-un-set-de-donnees-generant-un-gain-informationnel-maximal"><a href="#Determiner-la-feature-dans-un-set-de-donnees-generant-un-gain-informationnel-maximal" class="headerlink" title="Déterminer la feature dans un set de données générant un gain informationnel maximal"></a>Déterminer la feature dans un set de données générant un gain informationnel maximal</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">var</span> _ = <span class="built_in">require</span>(<span class="string">'lodash'</span>);</div><div class="line"><span class="keyword">var</span> data_set_splitter = <span class="built_in">require</span>(<span class="string">'./data_set_splitter'</span>)</div><div class="line"><span class="keyword">var</span> shannon_entropy = <span class="built_in">require</span>(<span class="string">'./shannon_entropy'</span>)</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">* This function will select the best feature for splittingwith the help</div><div class="line">* of the shannon entropy</div><div class="line">* @method get_the_best_feature_for_splitting</div><div class="line">* @param  &#123;Array&#125;                           data  A dataset of training, an array conposed of object with a property "label" that represents the class</div><div class="line">* @return &#123;String&#125;                                The name of the best feature for splitting (the property name)</div><div class="line">*/</div><div class="line"><span class="keyword">var</span>  get_the_best_feature_for_splitting= <span class="function"><span class="keyword">function</span>(<span class="params">data</span>)</span>&#123;</div><div class="line">  <span class="comment">// we compute the Entropy</span></div><div class="line">  <span class="keyword">var</span> base_entropy_value = shannon_entropy.calculate_shannon_entropy(data)</div><div class="line">  <span class="comment">// init a variable that will contain the best informational gain value</span></div><div class="line">  <span class="keyword">var</span> best_informational_gain_value = <span class="number">0</span></div><div class="line">  <span class="comment">// init a variable that will contain the best feature choice for splitting</span></div><div class="line">  <span class="keyword">var</span> best_feature_name = <span class="string">""</span></div><div class="line">  <span class="comment">// we iterate through our features (we take the first data element)</span></div><div class="line">  _.forEach(data[<span class="number">0</span>], <span class="function"><span class="keyword">function</span>(<span class="params">value_of_feature, feature_name</span>) </span>&#123;</div><div class="line">    <span class="keyword">if</span>(feature_name != <span class="string">"label"</span>)&#123;</div><div class="line"></div><div class="line"></div><div class="line">      <span class="comment">// get the unique values of each feature</span></div><div class="line">      <span class="keyword">var</span> unique_values_of_this_feature = _.uniq(_.map(data, feature_name));</div><div class="line">      <span class="comment">// init a variable that will contain the new_entropy_value</span></div><div class="line">      <span class="keyword">var</span> new_entropy_value = <span class="number">0</span>;</div><div class="line">      <span class="comment">// iterate through each possible value of this feature</span></div><div class="line">      _.forEach(unique_values_of_this_feature, <span class="function"><span class="keyword">function</span>(<span class="params">value_of_this_feature, key</span>) </span>&#123;</div><div class="line"></div><div class="line">        <span class="keyword">var</span>  data_set_without_this_feature_of_value = data_set_splitter.split_the_dataset_by_feature_and_value(data,feature_name,value_of_this_feature)</div><div class="line"></div><div class="line">        <span class="keyword">var</span> p = <span class="built_in">parseFloat</span>(data_set_without_this_feature_of_value.length/data.length)</div><div class="line">        new_entropy_value += p*shannon_entropy.calculate_shannon_entropy(data_set_without_this_feature_of_value)</div><div class="line"></div><div class="line">      &#125;)</div><div class="line"></div><div class="line">      <span class="comment">// we can now have the informational gain for this specific feature</span></div><div class="line">      <span class="keyword">var</span> informational_gain_value = base_entropy_value - new_entropy_value</div><div class="line">      <span class="comment">// if the informational gain value is higher than the best one</span></div><div class="line">      <span class="keyword">if</span>(informational_gain_value &gt; best_informational_gain_value)&#123;</div><div class="line">        <span class="comment">// it now become the best informational gain</span></div><div class="line">        best_informational_gain_value = informational_gain_value</div><div class="line">        <span class="comment">// and the best feature has to be keep in memory</span></div><div class="line">        best_feature_name = feature_name</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">  &#125;);</div><div class="line">  <span class="keyword">return</span> best_feature_name;</div><div class="line">&#125;</div><div class="line"></div><div class="line">get_the_best_feature_for_splitting(a)</div><div class="line"><span class="comment">// returns "has_a_car"</span></div><div class="line"></div><div class="line"><span class="built_in">module</span>.exports = &#123;</div><div class="line">  <span class="attr">get_the_best_feature_for_splitting</span>:get_the_best_feature_for_splitting</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Cette fonction doit détecter quelle est la feature qui apporte un gain informationnel maximal. Nous cherchons en effet à trouver la feature permettant de diviser nos exemples dans des “compartiments”, “compartiments” qui doivent avoir la particularité de regrouper des exemples de classes similaires, et ce dans une proportion la plus importante possible. Ainsi nous <code>réduisons le désordre</code>.</p>
<p>Dans les faits nous allons faire usage du calcul de l’entropie de Shannon pour calculer cette notion de différentiel de <code>désordre</code>.<br>Si on prend l’exemple de la feature <code>has_a_car</code>, on a donc deux valeurs possibles : <code>vrai</code> ou <code>faux</code>. Première étape : l’algorithme va donc générer un set de données ne contenant pas les exemples dont la <code>has_a_car</code> vaut <code>vrai</code>. On calcule ensuite le rapport entre le nombre d’éléments de notre nouveau set de données et le nombre d’élément que contient le set de données d’origine. On calcule ensuite l’entropie avec ce nouveau jeu de données. Ce processus est <strong>répété</strong> pour chaque valeur de la feature (donc 2 fois ici). On calcule ensuite pour chacune des feature le <code>gain informationnel</code>.</p>
<p>Ce dernier étant défini comme la différence entre l’entropie de base et la somme des entropies (pour chaque valeur de la feature). L’algorithme sélectionnera la feature qui permet d’obtenir le <strong>meilleur gain informationnel</strong> !</p>
<h3 id="Construction-de-l’arbre-de-decisions-de-maniere-recursive"><a href="#Construction-de-l’arbre-de-decisions-de-maniere-recursive" class="headerlink" title="Construction de l’arbre de décisions de manière récursive"></a>Construction de l’arbre de décisions de manière récursive</h3><p>Il est temps de construire notre arbre. Nous allons le faire grâce à l’usage d’une <strong>fonction récursive</strong>, c’est à dire une fonction qui va elle même s’appeler au cours de son exécution. Pour plus d’informations sur la récursivité rendez-vous sur la page wikipédia : <a href="https://fr.wikipedia.org/wiki/Fonction_r%C3%A9cursive" target="_blank" rel="external">https://fr.wikipedia.org/wiki/Fonction_r%C3%A9cursive</a>.</p>
<p>Lorsqu’on bâtit une fonction récursive il faut en premier lieu visualiser nos conditions de sorties. Nous allons donc itérer sur notre jeu de données d’entrainement afin à chaque fois de détecter la meilleur feature permettant de diviser notre jeu de données. Ainsi à chaque itération <strong>on isole la meilleure feature</strong>, on débarasse notre jeu de données de cette dernière. Cette meilleure feature sera donc une feuille de notre arbre. De cette feuille on aura autant de ramifications que de valeurs possibles à cette feature. Chaque feuille sera ensuite générée de suivant le même algorithme. Les conditions de sorties seront donc au nombre de deux :</p>
<ul>
<li>Il ne reste plus de features dans le jeu de données</li>
<li>Il ne reste plus que des objets ayant tous la même classe.</li>
</ul>
<p>Voici l’algorithme :</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> _ = <span class="built_in">require</span>(<span class="string">'lodash'</span>);</div><div class="line"><span class="keyword">var</span> data_set_splitter = <span class="built_in">require</span>(<span class="string">'./data_set_splitter'</span>)</div><div class="line"><span class="keyword">var</span> best_feature_selector = <span class="built_in">require</span>(<span class="string">'./best_feature_selector'</span>)</div><div class="line"><span class="keyword">var</span> shannon_entropy = <span class="built_in">require</span>(<span class="string">'./shannon_entropy'</span>)</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * This method will generate a decision tree</div><div class="line"> * @method generate_decision_tree</div><div class="line"> * @param  &#123;Array of object&#125;               data The dataset</div><div class="line"> * @return &#123;Object&#125;                    The decision tree/ ex : &#123;"has_a_car":&#123;"yes":&#123;"has_a_house":&#123;"yes":"good_borrower","no":"bad_borrower"&#125;&#125;,"no":"bad_borrower"&#125;&#125;</div><div class="line"> */</div><div class="line"><span class="keyword">var</span> generate_decision_tree = <span class="function"><span class="keyword">function</span>(<span class="params">data</span>)</span>&#123;</div><div class="line"></div><div class="line">  <span class="comment">// Because we build a recursive function</span></div><div class="line">  <span class="comment">// we have to set our stopping conditions at the</span></div><div class="line">  <span class="comment">// top.</span></div><div class="line"></div><div class="line">  <span class="comment">// group the dataset by label</span></div><div class="line">  <span class="keyword">var</span> grouped_data_per_label = _.groupBy(data, <span class="function"><span class="keyword">function</span>(<span class="params">o</span>)</span>&#123;</div><div class="line">    <span class="keyword">return</span> o.label</div><div class="line">  &#125;);</div><div class="line"></div><div class="line">  <span class="comment">// We stop when there are only elements of the same class</span></div><div class="line">  <span class="comment">// inside the dataset</span></div><div class="line">  <span class="comment">//</span></div><div class="line">  <span class="keyword">if</span>(_.size(grouped_data_per_label)===<span class="number">1</span>)&#123;</div><div class="line">    <span class="keyword">return</span> <span class="built_in">Object</span>.keys(grouped_data_per_label)[<span class="number">0</span>]</div><div class="line">  &#125;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">  <span class="comment">//  If there is no more features to split</span></div><div class="line">  <span class="comment">//  The size of the first training is only 1 because</span></div><div class="line">  <span class="comment">//  there is just one property the class</span></div><div class="line">  <span class="comment">//  ex : data[0] = &#123;"label":"good_borrower"&#125;</span></div><div class="line">  <span class="keyword">if</span>(_.size(data[<span class="number">0</span>])===<span class="number">1</span>)&#123;</div><div class="line">    <span class="keyword">return</span> mostly_present_class(data)</div><div class="line">  &#125;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">  <span class="comment">// Get the best feature to split</span></div><div class="line">  <span class="keyword">var</span> best_feature_for_splitting = best_feature_selector.get_the_best_feature_for_splitting(data)</div><div class="line"></div><div class="line">  <span class="comment">// create the object decision tree</span></div><div class="line">  <span class="keyword">var</span> decision_tree =&#123;&#125;</div><div class="line">  decision_tree[best_feature_for_splitting]=&#123;&#125;</div><div class="line"></div><div class="line">  <span class="comment">// we have then to extract the unique values of this feature in the dataset</span></div><div class="line">  <span class="comment">// get unique values of this feature</span></div><div class="line">  <span class="keyword">var</span> unique_values_of_best_feature =  _.uniq(_.map(data, best_feature_for_splitting));</div><div class="line">  <span class="comment">// forEach unique values of this feature</span></div><div class="line">  _.map(unique_values_of_best_feature, <span class="function"><span class="keyword">function</span>(<span class="params">value_of_this_feature</span>) </span>&#123;</div><div class="line"></div><div class="line"></div><div class="line">    <span class="comment">// We get the dataset cleaned of examples that have a feature "best_feature_for_splitting"</span></div><div class="line">    <span class="comment">// set to the value : "value_of_this_feature"</span></div><div class="line">    <span class="keyword">var</span> new_data_set = data_set_splitter.split_the_dataset_by_feature_and_value(data,best_feature_for_splitting,value_of_this_feature)</div><div class="line">    decision_tree[best_feature_for_splitting][value_of_this_feature] = generate_decision_tree(new_data_set);</div><div class="line"></div><div class="line">  &#125;);</div><div class="line"></div><div class="line"></div><div class="line">  <span class="keyword">return</span> decision_tree</div><div class="line"></div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line"><span class="built_in">module</span>.exports=&#123;</div><div class="line">  <span class="attr">generate_decision_tree</span> : generate_decision_tree</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>On obtient donc le résultat suivant pour notre set de données d’exemple :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123;&quot;has_a_car&quot;:&#123;&quot;yes&quot;:&#123;&quot;has_a_house&quot;:&#123;&quot;yes&quot;:&quot;good_borrower&quot;,&quot;no&quot;:&quot;bad_borrower&quot;&#125;&#125;,&quot;no&quot;:&quot;bad_borrower&quot;&#125;&#125;</div></pre></td></tr></table></figure>
<p>L’ensemble du code se trouve sur mon repo github : <a href="https://github.com/maximilienandile/decision_tree_example" target="_blank" rel="external">https://github.com/maximilienandile/decision_tree_example</a></p>

      
    </div>

    
      

    

    <footer class="article-footer">
      <a data-url="http://maximilienandile.github.io/2016/10/17/Machine-Learning-classification-a-l-aide-des-arbres-de-decisions-fonctionnement-et-application-en-NodeJS/" data-id="ciwwdjbnz000qyxkndt8kydq9" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
      
        <a href="http://maximilienandile.github.io/2016/10/17/Machine-Learning-classification-a-l-aide-des-arbres-de-decisions-fonctionnement-et-application-en-NodeJS/#disqus_thread" class="article-comment-link">
          <i class="fa fa-comment"></i> Comments
        </a>
      
      

    </footer>
  </div>
  
    
<ul id="article-nav" class="nav nav-pills nav-justified">
  
  <li role="presentation">
    <a href="/2016/10/12/Base-de-donnees-comprendre-les-differences-entre-le-modele-relationnel-et-le-modele-multidimensionnel/" id="article-nav-older" class="article-nav-link-wrap">
      <i class="fa fa-chevron-left pull-left"></i>
      <span class="article-nav-link-title">Base de données : comprendre les différences entre le modèle relationnel et le modèle multidimensionnel</span>
    </a>
  </li>
  
  
  <li role="presentation">
    <a href="/2016/11/02/Comment-creer-un-script-shell-permettant-de-recuperer-et-d-analyser-des-articles-wikipedia-avec-lynx/" id="article-nav-newer" class="article-nav-link-wrap">
      <span class="article-nav-link-title">Comment créer un script shell permettant de récupérer et d&#39;analyser des articles wikipedia avec lynx</span>
      <i class="fa fa-chevron-right pull-right"></i>
    </a>
  </li>
  
</ul>


  
</article>


<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>



        </div>
        <div class="col-sm-3 col-sm-offset-1 blog-sidebar">
          
  <div class="sidebar-module sidebar-module-inset">
  <h4>About</h4>
  <p>I am Maximilien Andile a Tech enthusiast and teacher who is always happy to share knowledge</p>

</div>


  


  
  <div class="sidebar-module">
    <h4>Tags</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Business-Intelligence/">Business Intelligence</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/HTTP/">HTTP</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Javascript/">Javascript</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Machine-Learning/">Machine Learning</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/NLP/">NLP</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Natural-Language-Processing/">Natural Language Processing</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Nodejs/">Nodejs</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/PHP/">PHP</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/PHP-Tests-unitaires/">PHP ; Tests unitaires</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/REST/">REST</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Recherche/">Recherche</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/SQL/">SQL</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/nodejs/">nodejs</a><span class="sidebar-module-list-count">1</span></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Tag Cloud</h4>
    <p class="tagcloud">
      <a href="/tags/Business-Intelligence/" style="font-size: 10px;">Business Intelligence</a> <a href="/tags/HTTP/" style="font-size: 10px;">HTTP</a> <a href="/tags/Javascript/" style="font-size: 20px;">Javascript</a> <a href="/tags/Machine-Learning/" style="font-size: 20px;">Machine Learning</a> <a href="/tags/NLP/" style="font-size: 20px;">NLP</a> <a href="/tags/Natural-Language-Processing/" style="font-size: 10px;">Natural Language Processing</a> <a href="/tags/Nodejs/" style="font-size: 10px;">Nodejs</a> <a href="/tags/PHP/" style="font-size: 10px;">PHP</a> <a href="/tags/PHP-Tests-unitaires/" style="font-size: 10px;">PHP ; Tests unitaires</a> <a href="/tags/REST/" style="font-size: 10px;">REST</a> <a href="/tags/Recherche/" style="font-size: 10px;">Recherche</a> <a href="/tags/SQL/" style="font-size: 10px;">SQL</a> <a href="/tags/nodejs/" style="font-size: 10px;">nodejs</a>
    </p>
  </div>


  
  <div class="sidebar-module">
    <h4>Archives</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2016/12/">décembre 2016</a><span class="sidebar-module-list-count">3</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2016/11/">novembre 2016</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2016/10/">octobre 2016</a><span class="sidebar-module-list-count">3</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2016/09/">septembre 2016</a><span class="sidebar-module-list-count">6</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2016/06/">juin 2016</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2016/05/">mai 2016</a><span class="sidebar-module-list-count">3</span></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Recents</h4>
    <ul class="sidebar-module-list">
      
        <li>
          <a href="/2016/12/19/Comment-utiliser-map-et-reduce-en-Javascript/">Comment utiliser map et reduce en Javascript</a>
        </li>
      
        <li>
          <a href="/2016/12/18/ES6-les-principales-features-a-connaitre/">ES6 : les principales features à connaître</a>
        </li>
      
        <li>
          <a href="/2016/12/18/l-ADN-une-nouvelle-source-de-stockage-de-donnees-durable/">ADN : une nouvelle source de stockage de données durable</a>
        </li>
      
        <li>
          <a href="/2016/11/02/Comment-creer-un-script-shell-permettant-de-recuperer-et-d-analyser-des-articles-wikipedia-avec-lynx/">Comment créer un script shell permettant de récupérer et d&#39;analyser des articles wikipedia avec lynx</a>
        </li>
      
        <li>
          <a href="/2016/10/17/Machine-Learning-classification-a-l-aide-des-arbres-de-decisions-fonctionnement-et-application-en-NodeJS/">Machine Learning : classification à l&#39;aide des arbres de décisions : fonctionnement et application en NodeJS</a>
        </li>
      
    </ul>
  </div>



        </div>
    </div>
  </div>
  <footer class="blog-footer">
  <div class="container">
    <div id="footer-info" class="inner">
      &copy; 2016 Maximilien Andile<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

  
<script>
  var disqus_shortname = 'maximilienandile';
  
  var disqus_url = 'http://maximilienandile.github.io/2016/10/17/Machine-Learning-classification-a-l-aide-des-arbres-de-decisions-fonctionnement-et-application-en-NodeJS/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js" integrity="sha384-8gBf6Y4YYq7Jx97PIqmTwLPin4hxIzQw5aDmUg/DDhul9fFpbbLcLh3nTIIDJKhx" crossorigin="anonymous"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>



<script src="/js/script.js"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

</body>
</html>
